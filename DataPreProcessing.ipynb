{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd42efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA CLEANING STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "225ee715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f22c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from the training datset file\n",
    "df_train = pd.read_csv('datasets/train3.csv', header='infer', low_memory=False)\n",
    "\n",
    "# Create dataframe from the testing datset file\n",
    "df_test = pd.read_csv('datasets/test3.csv', header='infer', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "249a8b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fun little place to stop and have lunch  There...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1307144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This place was PACKED  Went for late night foo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>5544361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We board the plane 30 minutes before the actua...</td>\n",
       "      <td>positive</td>\n",
       "      <td>5956200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chaotic 4 story place  but fun for kids  The w...</td>\n",
       "      <td>positive</td>\n",
       "      <td>718388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After (intentionally) capsizing a sailboat in ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>174754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55995</th>\n",
       "      <td>My new fav restaurant  by far!!!!  Its hard to...</td>\n",
       "      <td>positive</td>\n",
       "      <td>3794413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55996</th>\n",
       "      <td>Not sure why the great reviews  she abraded my...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3946261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55997</th>\n",
       "      <td>Food was okay  We had the all you can eat buff...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1237126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55998</th>\n",
       "      <td>Great place for after work drinks!!!  Went wit...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1532373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55999</th>\n",
       "      <td>Wow customer service re invented   I have noth...</td>\n",
       "      <td>positive</td>\n",
       "      <td>6458212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text     Class       ID\n",
       "0      Fun little place to stop and have lunch  There...  positive  1307144\n",
       "1      This place was PACKED  Went for late night foo...  negative  5544361\n",
       "2      We board the plane 30 minutes before the actua...  positive  5956200\n",
       "3      Chaotic 4 story place  but fun for kids  The w...  positive   718388\n",
       "4      After (intentionally) capsizing a sailboat in ...   neutral   174754\n",
       "...                                                  ...       ...      ...\n",
       "55995  My new fav restaurant  by far!!!!  Its hard to...  positive  3794413\n",
       "55996  Not sure why the great reviews  she abraded my...   neutral  3946261\n",
       "55997  Food was okay  We had the all you can eat buff...   neutral  1237126\n",
       "55998  Great place for after work drinks!!!  Went wit...  positive  1532373\n",
       "55999  Wow customer service re invented   I have noth...  positive  6458212\n",
       "\n",
       "[56000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if dataframes looks good\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "050f9cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>178</td>\n",
       "      <td>!:)I could pass out here and survive the zombi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>344</td>\n",
       "      <td>15% tips sneaked into our bill even though we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2324</td>\n",
       "      <td>How bad could it be? I thought  After all  its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3217</td>\n",
       "      <td>Jordan is awesome! I have a lot of muscle tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3705</td>\n",
       "      <td>Micheals Arts and CraftsWell  they live under ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>6662447</td>\n",
       "      <td>wifi doesnt work  Also  even it works  it is v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>6662575</td>\n",
       "      <td>wish I could select zero stars   This place wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>6664830</td>\n",
       "      <td>ya know this place is so good  and so unassumi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>6665591</td>\n",
       "      <td>you definitely dont want to bring a first date...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>6666002</td>\n",
       "      <td>yum the grilled pineapple is amazing  The pork...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               Text\n",
       "0          178  !:)I could pass out here and survive the zombi...\n",
       "1          344  15% tips sneaked into our bill even though we ...\n",
       "2         2324  How bad could it be? I thought  After all  its...\n",
       "3         3217  Jordan is awesome! I have a lot of muscle tens...\n",
       "4         3705  Micheals Arts and CraftsWell  they live under ...\n",
       "...        ...                                                ...\n",
       "13995  6662447  wifi doesnt work  Also  even it works  it is v...\n",
       "13996  6662575  wish I could select zero stars   This place wa...\n",
       "13997  6664830  ya know this place is so good  and so unassumi...\n",
       "13998  6665591  you definitely dont want to bring a first date...\n",
       "13999  6666002  yum the grilled pineapple is amazing  The pork...\n",
       "\n",
       "[14000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87f7a184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56000 entries, 0 to 55999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    56000 non-null  object\n",
      " 1   Class   56000 non-null  object\n",
      " 2   ID      56000 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 875.1+ KB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14000 entries, 0 to 13999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      14000 non-null  int64 \n",
      " 1   Text    14000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 164.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# View all columns and their data types\n",
    "df_train.info()\n",
    "print('\\n')\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fffb5730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ID columns from both dataframes\n",
    "del df_train['ID']\n",
    "del df_test['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b303d4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before \n",
      "This place was PACKED  Went for late night food  They serve late which is awesome  Ended up having to get our food to go because they had 1 cook & he got slammed w/ orders  I got pork schnitzel sandwich  The breading was dark but still good   however there was NO  potato salad on sandwich as described   Disappointing   Boyfriend ordered the spicy burger ($9) He said it was OK  He wasnt super impressed  Waffle fries were good  Prices are reasonable  Debating whether wed give them another shot \n",
      "\n",
      "After \n",
      "this place was packed  went for late night food  they serve late which is awesome  ended up having to get our food to go because they had 1 cook & he got slammed w/ orders  i got pork schnitzel sandwich  the breading was dark but still good   however there was no  potato salad on sandwich as described   disappointing   boyfriend ordered the spicy burger ($9) he said it was ok  he wasnt super impressed  waffle fries were good  prices are reasonable  debating whether wed give them another shot \n"
     ]
    }
   ],
   "source": [
    "# Word Extraction\n",
    "\n",
    "# Convert all words to lowercase to avoid duplicate words in different fields\n",
    "print('Before \\n' + df_train['Text'][1] + '\\n')\n",
    "df_train['Text'] = df_train['Text'].str.lower()\n",
    "df_test['Text'] = df_test['Text'].str.lower()\n",
    "print('After \\n' + df_train['Text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cbe5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace some slang and word meanings based on our judgement in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb4225fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace some 'hello' in other languages than english usually being correlated to positive reviews\n",
    "hellos = ['aloha', 'bonjour', 'namaste']\n",
    "\n",
    "for hello in hellos:\n",
    "    df_train['Text'] = df_train['Text'].str.replace(hello, 'happy', regex=False)\n",
    "    df_test['Text'] = df_test['Text'].str.replace(hello, 'happy', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffab50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace some short terms usually correlating with reviews\n",
    "goods = ['lol', 'atm']\n",
    "bads = ['smh', ' fk', 'lmfao', 'rip', 'wtf']\n",
    "neutrals = ['aight']\n",
    "\n",
    "for good in goods:\n",
    "    df_train['Text'] = df_train['Text'].str.replace(good, 'happy', regex=False)\n",
    "    df_test['Text'] = df_test['Text'].str.replace(good, 'happy', regex=False)\n",
    "\n",
    "for bad in bads:\n",
    "    df_train['Text'] = df_train['Text'].str.replace(bad, 'bad', regex=False)\n",
    "    df_test['Text'] = df_test['Text'].str.replace(bad, 'bad', regex=False)\n",
    "    \n",
    "for neutral in neutrals:\n",
    "    df_train['Text'] = df_train['Text'].str.replace(neutral, 'neutral', regex=False)\n",
    "    df_test['Text'] = df_test['Text'].str.replace(neutral, 'neutral', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f92eabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before \n",
      "decided to finally try out this spot since we had passed it at least once a week heading to citizen for coffee  its hard to find parking for this little joint so you may need to walk a little but we felt it was definitely worth it  we sat at the tables outdoors where they have a nice little patio setup  the staff were very friendly and if you go for brunch you can start your day with a nice mimosa bucket  they have everything from breakfast items  sandwiches  salads  and meat entries  the food was great it tasted home grown with only the best ingredients  we will definitely be coming back in the future  only we wont wait so long this time : )\n",
      "\n",
      "After \n",
      "decided to finally try out this spot since we had passed it at least once a week heading to citizen for coffee  its hard to find parking for this little joint so you may need to walk a little but we felt it was definitely worth it  we sat at the tables outdoors where they have a nice little patio setup  the staff were very friendly and if you go for brunch you can start your day with a nice mimosa bucket  they have everything from breakfast items  sandwiches  salads  and meat entries  the food was great it tasted home grown with only the best ingredients  we will definitely be coming back in the future  only we wont wait so long this time happy\n"
     ]
    }
   ],
   "source": [
    "# Replace variations of smiley faces to correlate to happy and bad\n",
    "happy = [':)', ': )', ':  )', ':]', ': ]', ':  ]', ':}', ': }', ':  }', ';)', '; )', ';  )', ';]', '; ]', ';  ]', ';}', '; }', ';  }']\n",
    "bad = [':(', ': (', ':  (', ':[', ': [', ':  [', ':{', ': {', ':  {', ';(', '; (', ';  (', ';[', '; [', ';  [', ';{', '; {', ';  {']\n",
    "\n",
    "print('Before \\n' + df_train['Text'][2916] + '\\n')\n",
    "\n",
    "for face in happy:\n",
    "    df_train['Text'] = df_train['Text'].str.replace(face, 'happy', regex=False)\n",
    "    df_test['Text'] = df_test['Text'].str.replace(face, 'happy', regex=False)\n",
    "\n",
    "for face in bad:\n",
    "    df_train['Text'] = df_train['Text'].str.replace(face, 'bad', regex=False)\n",
    "    df_test['Text'] = df_test['Text'].str.replace(face, 'bad', regex=False)\n",
    "    \n",
    "print('After \\n' + df_train['Text'][2916])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf38ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Placing Fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d01819aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before \n",
      "i love pizza!!tonys has a great lunch special  a slice of pizza with a side salad or garlic knots and a drink for like $6 50 the pizza is great! i have been just for a slice and also for a pie with the fam! my dad used to get the sausage and peppers and really liked it  the salad is good with the mozzarella on top of it and the italian dressing its perfect for a quick bite or to pick up  i do suggest if you dine in and want a pie  to order everything beforehand and then get there and enjoy it without the wait!\n",
      "\n",
      "After \n",
      "i love pizza !  ! tonys has a great lunch special  a slice of pizza with a side salad or garlic knots and a drink for like $6 50 the pizza is great !  i have been just for a slice and also for a pie with the fam !  my dad used to get the sausage and peppers and really liked it  the salad is good with the mozzarella on top of it and the italian dressing its perfect for a quick bite or to pick up  i do suggest if you dine in and want a pie  to order everything beforehand and then get there and enjoy it without the wait ! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a space between some special characters so we can later easily distinguish them into seperate words\n",
    "print('Before \\n' + df_train['Text'][14] + '\\n')\n",
    "df_train['Text'] = df_train['Text'].str.replace('!', ' ! ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('?', ' ? ', regex=False)\n",
    "print('After \\n' + df_train['Text'][14] + '\\n')\n",
    "\n",
    "df_test['Text'] = df_test['Text'].str.replace('!', ' ! ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('?', ' ? ', regex=False)\n",
    "\n",
    "# Remove some special characters that have no significance\n",
    "df_train['Text'] = df_train['Text'].str.replace('(', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace(')', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('[', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace(']', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('{', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('}', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('/', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('@', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('&', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('*', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace(';', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace(':', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('~', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('|', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('^', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('<', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('>', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('_', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('#', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('%', ' ', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace('@', ' ', regex=False)\n",
    "\n",
    "df_test['Text'] = df_test['Text'].str.replace('(', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace(')', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('[', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace(']', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('{', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('}', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('/', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('@', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('&', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('*', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace(';', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace(':', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('~', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('|', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('^', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('<', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('>', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('_', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('#', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('%', ' ', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace('@', ' ', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33320441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f12a895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before \n",
      "fun little place to stop and have lunch  there was plenty of parking out back  and more tables on the patio than there was inside  the lunch menu has all the basics  i chose the turkey sandwich which was very moist and tasty  i also ordered a strawberry banana smoothie which hit the spot on this hot day  this a dog friendly place that has tie outs here and there \n",
      "\n",
      "After \n",
      "fun little place stop lunch  plenty parking  tables patio inside  lunch menu basics  chose turkey sandwich moist tasty  ordered strawberry banana smoothie hit spot hot day  dog friendly place tie outs \n"
     ]
    }
   ],
   "source": [
    "# Remove words included in stop_words.txt\n",
    "print('Before \\n' + df_train['Text'][0] + '\\n')\n",
    "\n",
    "with open('datasets/stop_words.txt', 'r') as file:\n",
    "    data = file.read().splitlines()\n",
    "\n",
    "for d in data:\n",
    "    df_train['Text'] = df_train['Text'].str.replace(' ' + d + ' ',' ')\n",
    "    df_test['Text'] = df_test['Text'].str.replace(' ' + d + ' ',' ')\n",
    "\n",
    "print('After \\n' + df_train['Text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd886031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edd88543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant '.' & ','\n",
    "\n",
    "df_train['Text'] = df_train['Text'].str.replace('.', '', regex=False)\n",
    "df_train['Text'] = df_train['Text'].str.replace(',', '', regex=False)\n",
    "\n",
    "df_test['Text'] = df_test['Text'].str.replace('.', '', regex=False)\n",
    "df_test['Text'] = df_test['Text'].str.replace(',', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "346bef32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before \n",
      "i minus  scheduled appointment seen sinus infection drainage ear canals  informed  dr  chiara symptoms  going couple months  told severe hearing loss  prescribed antibiotic  created severe gi distress scheduled meet audiologist hearing aids examining ear s determine need hearing aids  looking new better ent  dont waste time  place laughable !  !  ! \n",
      "\n",
      "After \n",
      "i minus scheduled appointment seen sinus infection drainage ear canals informed symptoms going couple months told severe hearing loss prescribed antibiotic created severe gi distress scheduled meet hearing aids examining ear s determine need hearing aids looking new better waste time place laughable ! ! !\n"
     ]
    }
   ],
   "source": [
    "# Remove words that arent in the dictionary\n",
    "\n",
    "print('Before \\n' + df_train['Text'][137] + '\\n')\n",
    "regex = re.compile('[@_!#$%^&*()<>?/\\|}{~:]')\n",
    "def valid_words(Text):\n",
    "    tokenized_words = nltk.word_tokenize(Text)\n",
    "    tokenized_sentence = []\n",
    "    for word in tokenized_words:\n",
    "        if wordnet.synsets(word):\n",
    "            tokenized_sentence.append(word)\n",
    "        elif len(word) is 1 and regex.search(word) is not None:\n",
    "            tokenized_sentence.append(word)\n",
    "    tokenized_sentence = \" \".join(tokenized_sentence)\n",
    "    return tokenized_sentence\n",
    "\n",
    "df_train['Text'] = df_train['Text'].apply(valid_words)\n",
    "df_test['Text'] = df_test['Text'].apply(valid_words)\n",
    "print('After \\n' + df_train['Text'][137])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd95860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before \n",
      " i minus scheduled appointment seen sinus infection drainage ear canals informed symptoms going couple months told severe hearing loss prescribed antibiotic created severe gi distress scheduled meet hearing aids examining ear s determine need hearing aids looking new better waste time place laughable ! ! !\n",
      "\n",
      "After \n",
      " minus scheduled appointment seen sinus infection drainage ear canals informed symptoms going couple months told severe hearing loss prescribed antibiotic created severe gi distress scheduled meet hearing aids examining ear determine need hearing aids looking new better waste time place laughable ! ! !\n"
     ]
    }
   ],
   "source": [
    "# Remove single letter words\n",
    "\n",
    "df_train['Text'] = ' ' + df_train['Text']\n",
    "df_test['Text'] = ' ' + df_test['Text']\n",
    "\n",
    "print('Before \\n' + df_train['Text'][137] + '\\n')\n",
    "alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "for letter in alphabet:\n",
    "    df_train['Text'] = df_train['Text'].str.replace(' ' + letter + ' ', ' ', regex=False)\n",
    "    df_test['Text'] = df_test['Text'].str.replace(' ' + letter + ' ', ' ', regex=False)\n",
    "    \n",
    "print('After \\n' + df_train['Text'][137])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1b1b238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before \n",
      " dog teddy groomed dropped let know exactly wanted told use 3 4 inch clippers leave paws fluffy head went pick mortified life did come drop receptionist went grab know head oddly shaped small fur legs longer index finger oh paws completely shaved soap body hair definitely 3 4 inch face shaved small unbearable haircut offered talk touch decided best touch hair\n",
      "\n",
      "After \n",
      " dog teddy groomed dropped let know exactly wanted told use   inch clippers leave paws fluffy head went pick mortified life did come drop receptionist went grab know head oddly shaped small fur legs longer index finger oh paws completely shaved soap body hair definitely   inch face shaved small unbearable haircut offered talk touch decided best touch hair\n"
     ]
    }
   ],
   "source": [
    "# Remove all numeric values in the text\n",
    "\n",
    "print('Before \\n' + df_train['Text'][200] + '\\n')\n",
    "df_train['Text'] = df_train['Text'].str.replace('\\d+', '', regex=True)\n",
    "df_test['Text'] = df_test['Text'].str.replace('\\d+', '', regex=True)\n",
    "print('After \\n' + df_train['Text'][200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bf667a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omitted at the moment, the stemming seems to really make the words too vague. Ex) exactly -> exactli\n",
    "# Apply Porter Stemming Algorithim\n",
    "\n",
    "# print('Before \\n' + df_train['Text'][2] + '\\n')\n",
    "# porter = PorterStemmer()\n",
    "\n",
    "# def stem_text(Text):\n",
    "#     tokenized_words = nltk.word_tokenize(Text)\n",
    "#     tokenized_sentence = []\n",
    "#     for word in tokenized_words:\n",
    "#         tokenized_sentence.append(porter.stem(word))\n",
    "#     tokenized_sentence = \" \".join(tokenized_sentence)\n",
    "#     return tokenized_sentence\n",
    "\n",
    "# df_train['Text'] = df_train['Text'].apply(stem_text)\n",
    "# df_test['Text'] = df_test['Text'].apply(stem_text)\n",
    "# print('After \\n' + df_train['Text'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65d5f1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before \n",
      " minus scheduled appointment seen sinus infection drainage ear canals informed symptoms going couple months told severe hearing loss prescribed antibiotic created severe gi distress scheduled meet hearing aids examining ear determine need hearing aids looking new better waste time place laughable ! ! !\n",
      "\n",
      "After \n",
      "minus schedule appointment see sinus infection drainage ear canal inform symptom go couple month tell severe hear loss prescribe antibiotic create severe gi distress schedule meet hear aid examine ear determine need hear aid look new good waste time place laughable ! ! !\n"
     ]
    }
   ],
   "source": [
    "# Apply Lemmatization to the dataset\n",
    "\n",
    "print('Before \\n' + df_train['Text'][137] + '\\n')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(Text):\n",
    "    tokenized_words = nltk.word_tokenize(Text)\n",
    "    tokenized_sentence = []\n",
    "    for word in tokenized_words:\n",
    "        new_word = lemmatizer.lemmatize(word, pos=\"n\")\n",
    "        new_word = lemmatizer.lemmatize(new_word, pos=\"a\")\n",
    "        new_word = lemmatizer.lemmatize(new_word, pos=\"v\")\n",
    "        tokenized_sentence.append(new_word)\n",
    "    tokenized_sentence = \" \".join(tokenized_sentence)\n",
    "    return tokenized_sentence\n",
    "\n",
    "df_train['Text'] = df_train['Text'].apply(lemmatize_text)\n",
    "df_test['Text'] = df_test['Text'].apply(lemmatize_text)\n",
    "print('After \\n' + df_train['Text'][137])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b42d9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    54496\n",
       "True      1504\n",
       "Name: Text_As_Word_List, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new column which will have the reviews represented as a word list\n",
    "\n",
    "# Turn the datafram column for reviews into a list of words for easier analysis\n",
    "df_train['Text_As_Word_List'] = df_train.Text.apply(lambda x: x.split(' '))\n",
    "df_test['Text_As_Word_List'] = df_test.Text.apply(lambda x: x.split(' '))\n",
    "\n",
    "# See how many reviews contain a set of words or not\n",
    "df_train.Text_As_Word_List.map(set(['leave', '!']).issubset).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f7d652d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'place': [2], 'lunch': [2], 'fun': [1], 'little': [1], 'stop': [1], 'plenty': [1], 'park': [1], 'table': [1], 'patio': [1], 'inside': [1], 'menu': [1], 'basic': [1], 'choose': [1], 'turkey': [1], 'sandwich': [1], 'moist': [1], 'tasty': [1], 'order': [1], 'strawberry': [1], 'banana': [1], 'smoothie': [1], 'hit': [1], 'spot': [1], 'hot': [1], 'day': [1], 'dog': [1], 'friendly': [1], 'tie': [1], 'out': [1]})\n"
     ]
    }
   ],
   "source": [
    "# Create new column which will have the reviews represented as a frequency count dictionary\n",
    "\n",
    "def convert_to_dict(Text_As_Word_List):\n",
    "    words_to_count = (word for word in Text_As_Word_List)\n",
    "    c = Counter(words_to_count)\n",
    "    freq = c.most_common(len(c))\n",
    "    dict = defaultdict(list)\n",
    "    for k, v in freq:\n",
    "        dict[k].append(v)\n",
    "    return dict\n",
    "\n",
    "df_train['Text_As_Freq_Dict'] = df_train['Text_As_Word_List'].apply(convert_to_dict)\n",
    "df_test['Text_As_Freq_Dict'] = df_test['Text_As_Word_List'].apply(convert_to_dict)\n",
    "\n",
    "print(df_train['Text_As_Freq_Dict'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8edd96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('!', 70240),\n",
       " ('good', 27716),\n",
       " ('place', 25812),\n",
       " ('food', 24380),\n",
       " ('great', 23104),\n",
       " ('service', 18470),\n",
       " ('time', 18048),\n",
       " ('come', 15482),\n",
       " ('like', 14466),\n",
       " ('order', 13349),\n",
       " ('just', 13090),\n",
       " ('go', 12025),\n",
       " ('get', 11108),\n",
       " ('love', 10767),\n",
       " ('try', 10681),\n",
       " ('really', 10402),\n",
       " ('price', 8630),\n",
       " ('best', 8602),\n",
       " ('nice', 8469),\n",
       " ('say', 8139),\n",
       " ('staff', 8122),\n",
       " ('friendly', 7946),\n",
       " ('$', 7867),\n",
       " ('make', 7429),\n",
       " ('look', 7382),\n",
       " ('wait', 7248),\n",
       " ('do', 7129),\n",
       " ('recommend', 7070),\n",
       " ('restaurant', 6919),\n",
       " ('amaze', 6850),\n",
       " ('definitely', 6796),\n",
       " ('want', 6699),\n",
       " ('eat', 6633),\n",
       " ('?', 6266),\n",
       " ('work', 6252),\n",
       " ('chicken', 5968),\n",
       " ('delicious', 5955),\n",
       " ('experience', 5899),\n",
       " ('drink', 5732),\n",
       " ('need', 5719),\n",
       " ('take', 5666),\n",
       " ('little', 5579),\n",
       " ('bad', 5554),\n",
       " ('day', 5548),\n",
       " ('happy', 5511),\n",
       " ('know', 5484),\n",
       " ('think', 5269),\n",
       " ('people', 5213),\n",
       " ('taste', 4987),\n",
       " ('ask', 4885),\n",
       " ('customer', 4878),\n",
       " ('pretty', 4840),\n",
       " ('menu', 4799),\n",
       " ('pizza', 4752),\n",
       " ('new', 4735),\n",
       " ('fry', 4661),\n",
       " ('thing', 4615),\n",
       " ('location', 4568),\n",
       " ('clean', 4468),\n",
       " ('use', 4455),\n",
       " ('lot', 4417),\n",
       " ('tell', 4388),\n",
       " ('fresh', 4318),\n",
       " ('year', 4268),\n",
       " ('way', 4237),\n",
       " ('hour', 4161),\n",
       " ('night', 4151),\n",
       " ('bar', 4129),\n",
       " ('star', 4128),\n",
       " ('bite', 4108),\n",
       " ('sure', 4056),\n",
       " ('friend', 4028),\n",
       " ('right', 3959),\n",
       " ('vega', 3935),\n",
       " ('minute', 3919),\n",
       " ('visit', 3868),\n",
       " ('table', 3802),\n",
       " ('awesome', 3795),\n",
       " ('lunch', 3793),\n",
       " ('give', 3685),\n",
       " ('small', 3677),\n",
       " ('enjoy', 3636),\n",
       " ('area', 3628),\n",
       " ('long', 3610),\n",
       " ('salad', 3587),\n",
       " ('feel', 3512),\n",
       " ('burger', 3485),\n",
       " ('leave', 3454),\n",
       " ('excellent', 3441),\n",
       " ('sauce', 3398),\n",
       " ('meal', 3390),\n",
       " ('super', 3389),\n",
       " ('room', 3363),\n",
       " ('check', 3336),\n",
       " ('worth', 3295),\n",
       " ('walk', 3272),\n",
       " ('store', 3220),\n",
       " ('review', 3209),\n",
       " ('favorite', 3110),\n",
       " ('pay', 3074)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the most occured words in the dataset\n",
    "\n",
    "Counter(\" \".join(df_train[\"Text\"]).split()).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb8fab3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text_As_Word_List</th>\n",
       "      <th>Text_As_Freq_Dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fun little place stop lunch plenty park table ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[fun, little, place, stop, lunch, plenty, park...</td>\n",
       "      <td>{'place': [2], 'lunch': [2], 'fun': [1], 'litt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>place pack go late night food serve late aweso...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[place, pack, go, late, night, food, serve, la...</td>\n",
       "      <td>{'late': [2], 'food': [2], 'get': [2], 'order'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>board plane minute actual flight make sure lea...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[board, plane, minute, actual, flight, make, s...</td>\n",
       "      <td>{'flight': [4], '!': [4], 'minute': [3], 'hour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chaotic story place fun kid white chocolate m ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[chaotic, story, place, fun, kid, white, choco...</td>\n",
       "      <td>{'chaotic': [1], 'story': [1], 'place': [1], '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>after intentionally capsize sailboat spend goo...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[after, intentionally, capsize, sailboat, spen...</td>\n",
       "      <td>{'after': [1], 'intentionally': [1], 'capsize'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55995</th>\n",
       "      <td>new restaurant far ! ! ! ! hard remember time ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[new, restaurant, far, !, !, !, !, hard, remem...</td>\n",
       "      <td>{'!': [5], 'new': [1], 'restaurant': [1], 'far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55996</th>\n",
       "      <td>not sure great review abrade big toe keep get ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[not, sure, great, review, abrade, big, toe, k...</td>\n",
       "      <td>{'?': [4], 'not': [1], 'sure': [1], 'great': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55997</th>\n",
       "      <td>food okay eat buffet waiter keep get order wro...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[food, okay, eat, buffet, waiter, keep, get, o...</td>\n",
       "      <td>{'food': [1], 'okay': [1], 'eat': [1], 'buffet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55998</th>\n",
       "      <td>great place work drink ! ! ! go team friday dr...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[great, place, work, drink, !, !, !, go, team,...</td>\n",
       "      <td>{'!': [4], 'drink': [2], 'go': [2], 'great': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55999</th>\n",
       "      <td>wow customer service invent good thing say guy...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wow, customer, service, invent, good, thing, ...</td>\n",
       "      <td>{'pool': [4], 'customer': [2], 'thing': [2], '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text     Class  \\\n",
       "0      fun little place stop lunch plenty park table ...  positive   \n",
       "1      place pack go late night food serve late aweso...  negative   \n",
       "2      board plane minute actual flight make sure lea...  positive   \n",
       "3      chaotic story place fun kid white chocolate m ...  positive   \n",
       "4      after intentionally capsize sailboat spend goo...   neutral   \n",
       "...                                                  ...       ...   \n",
       "55995  new restaurant far ! ! ! ! hard remember time ...  positive   \n",
       "55996  not sure great review abrade big toe keep get ...   neutral   \n",
       "55997  food okay eat buffet waiter keep get order wro...   neutral   \n",
       "55998  great place work drink ! ! ! go team friday dr...  positive   \n",
       "55999  wow customer service invent good thing say guy...  positive   \n",
       "\n",
       "                                       Text_As_Word_List  \\\n",
       "0      [fun, little, place, stop, lunch, plenty, park...   \n",
       "1      [place, pack, go, late, night, food, serve, la...   \n",
       "2      [board, plane, minute, actual, flight, make, s...   \n",
       "3      [chaotic, story, place, fun, kid, white, choco...   \n",
       "4      [after, intentionally, capsize, sailboat, spen...   \n",
       "...                                                  ...   \n",
       "55995  [new, restaurant, far, !, !, !, !, hard, remem...   \n",
       "55996  [not, sure, great, review, abrade, big, toe, k...   \n",
       "55997  [food, okay, eat, buffet, waiter, keep, get, o...   \n",
       "55998  [great, place, work, drink, !, !, !, go, team,...   \n",
       "55999  [wow, customer, service, invent, good, thing, ...   \n",
       "\n",
       "                                       Text_As_Freq_Dict  \n",
       "0      {'place': [2], 'lunch': [2], 'fun': [1], 'litt...  \n",
       "1      {'late': [2], 'food': [2], 'get': [2], 'order'...  \n",
       "2      {'flight': [4], '!': [4], 'minute': [3], 'hour...  \n",
       "3      {'chaotic': [1], 'story': [1], 'place': [1], '...  \n",
       "4      {'after': [1], 'intentionally': [1], 'capsize'...  \n",
       "...                                                  ...  \n",
       "55995  {'!': [5], 'new': [1], 'restaurant': [1], 'far...  \n",
       "55996  {'?': [4], 'not': [1], 'sure': [1], 'great': [...  \n",
       "55997  {'food': [1], 'okay': [1], 'eat': [1], 'buffet...  \n",
       "55998  {'!': [4], 'drink': [2], 'go': [2], 'great': [...  \n",
       "55999  {'pool': [4], 'customer': [2], 'thing': [2], '...  \n",
       "\n",
       "[56000 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the finalized schema\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4a3fbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_As_Word_List</th>\n",
       "      <th>Text_As_Freq_Dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>! pas survive zombie apocalypse bathroom decor...</td>\n",
       "      <td>[!, pas, survive, zombie, apocalypse, bathroom...</td>\n",
       "      <td>{'!': [9], 'like': [2], '?': [2], 'spend': [2]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tip sneak get crappy service busy obvious reas...</td>\n",
       "      <td>[tip, sneak, get, crappy, service, busy, obvio...</td>\n",
       "      <td>{'ask': [4], 'service': [2], 'come': [2], 'lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad ? think close home winter ill wear hat per...</td>\n",
       "      <td>[bad, ?, think, close, home, winter, ill, wear...</td>\n",
       "      <td>{'home': [2], 'ill': [2], 'hat': [2], 'say': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jordan awesome ! lot muscle tension cause head...</td>\n",
       "      <td>[jordan, awesome, !, lot, muscle, tension, cau...</td>\n",
       "      <td>{'jordan': [1], 'awesome': [1], '!': [1], 'lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>art live ! art craft book paint brush art tool...</td>\n",
       "      <td>[art, live, !, art, craft, book, paint, brush,...</td>\n",
       "      <td>{'art': [3], 'stuff': [2], 'live': [1], '!': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>wifi work work stupid customer bring laptop co...</td>\n",
       "      <td>[wifi, work, work, stupid, customer, bring, la...</td>\n",
       "      <td>{'work': [2], 'wifi': [1], 'stupid': [1], 'cus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>wish select zero star place bad anticipate bui...</td>\n",
       "      <td>[wish, select, zero, star, place, bad, anticip...</td>\n",
       "      <td>{'bad': [2], 'minute': [2], 'doctor': [2], 'ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>know place good unassuming great food awesome ...</td>\n",
       "      <td>[know, place, good, unassuming, great, food, a...</td>\n",
       "      <td>{'really': [3], 'good': [2], 'food': [2], 'awe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>definitely want bring date ready sloppy lick f...</td>\n",
       "      <td>[definitely, want, bring, date, ready, sloppy,...</td>\n",
       "      <td>{'lot': [2], 'definitely': [1], 'want': [1], '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>grill pineapple amaze pork belly appetizer ove...</td>\n",
       "      <td>[grill, pineapple, amaze, pork, belly, appetiz...</td>\n",
       "      <td>{'grill': [1], 'pineapple': [1], 'amaze': [1],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "0      ! pas survive zombie apocalypse bathroom decor...   \n",
       "1      tip sneak get crappy service busy obvious reas...   \n",
       "2      bad ? think close home winter ill wear hat per...   \n",
       "3      jordan awesome ! lot muscle tension cause head...   \n",
       "4      art live ! art craft book paint brush art tool...   \n",
       "...                                                  ...   \n",
       "13995  wifi work work stupid customer bring laptop co...   \n",
       "13996  wish select zero star place bad anticipate bui...   \n",
       "13997  know place good unassuming great food awesome ...   \n",
       "13998  definitely want bring date ready sloppy lick f...   \n",
       "13999  grill pineapple amaze pork belly appetizer ove...   \n",
       "\n",
       "                                       Text_As_Word_List  \\\n",
       "0      [!, pas, survive, zombie, apocalypse, bathroom...   \n",
       "1      [tip, sneak, get, crappy, service, busy, obvio...   \n",
       "2      [bad, ?, think, close, home, winter, ill, wear...   \n",
       "3      [jordan, awesome, !, lot, muscle, tension, cau...   \n",
       "4      [art, live, !, art, craft, book, paint, brush,...   \n",
       "...                                                  ...   \n",
       "13995  [wifi, work, work, stupid, customer, bring, la...   \n",
       "13996  [wish, select, zero, star, place, bad, anticip...   \n",
       "13997  [know, place, good, unassuming, great, food, a...   \n",
       "13998  [definitely, want, bring, date, ready, sloppy,...   \n",
       "13999  [grill, pineapple, amaze, pork, belly, appetiz...   \n",
       "\n",
       "                                       Text_As_Freq_Dict  \n",
       "0      {'!': [9], 'like': [2], '?': [2], 'spend': [2]...  \n",
       "1      {'ask': [4], 'service': [2], 'come': [2], 'lit...  \n",
       "2      {'home': [2], 'ill': [2], 'hat': [2], 'say': [...  \n",
       "3      {'jordan': [1], 'awesome': [1], '!': [1], 'lot...  \n",
       "4      {'art': [3], 'stuff': [2], 'live': [1], '!': [...  \n",
       "...                                                  ...  \n",
       "13995  {'work': [2], 'wifi': [1], 'stupid': [1], 'cus...  \n",
       "13996  {'bad': [2], 'minute': [2], 'doctor': [2], 'ca...  \n",
       "13997  {'really': [3], 'good': [2], 'food': [2], 'awe...  \n",
       "13998  {'lot': [2], 'definitely': [1], 'want': [1], '...  \n",
       "13999  {'grill': [1], 'pineapple': [1], 'amaze': [1],...  \n",
       "\n",
       "[14000 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf5d11cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56000 entries, 0 to 55999\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Text               56000 non-null  object\n",
      " 1   Class              56000 non-null  object\n",
      " 2   Text_As_Word_List  56000 non-null  object\n",
      " 3   Text_As_Freq_Dict  56000 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 875.1+ KB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14000 entries, 0 to 13999\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Text               14000 non-null  object\n",
      " 1   Text_As_Word_List  14000 non-null  object\n",
      " 2   Text_As_Freq_Dict  14000 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 164.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# View the finalized schema statistics\n",
    "\n",
    "df_train.info()\n",
    "print('\\n')\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8699778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the pre processed training and test dataframes to a csv file\n",
    "\n",
    "df_train['Text_As_Freq_Dict'] = df_train['Text_As_Freq_Dict'].astype(str)\n",
    "df_test['Text_As_Freq_Dict'] = df_test['Text_As_Freq_Dict'].astype(str)\n",
    "\n",
    "df_train['Text_As_Freq_Dict'] = df_train['Text_As_Freq_Dict'].str.slice(28, -1)\n",
    "df_test['Text_As_Freq_Dict'] = df_test['Text_As_Freq_Dict'].str.slice(28, -1)\n",
    "\n",
    "df_train.to_csv('cleaned_datasets/cleaned_training_data.csv', index=False)\n",
    "df_test.to_csv('cleaned_datasets/cleaned_test_data.csv', index=False)\n",
    "\n",
    "# Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
